{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c30c6c3-609b-46b0-a3cd-95a86388f589",
   "metadata": {},
   "source": [
    "# News Classification with DistilBERT and comparison across mulitple models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1dd432-abe1-48b2-8d24-af915b50f66a",
   "metadata": {},
   "source": [
    "# Acknowledgement\n",
    "- https://www.kaggle.com/code/vbmokin/nlp-for-en-bert-cls-10-classifiers\n",
    "\n",
    "\n",
    "# Description\n",
    "\n",
    "The original Kaggle notebook applied these binary classification with DistilBERT word embeddings across every label. I'm repurposing this work to apply a multinomial classification for all labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15697efe-52ea-43a2-be51-fe606900c382",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9070144f-9668-44f9-b4c9-5d83650dc573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-13 13:26:08.110546: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/home/lpieri/mambaforge/envs/news-ml-exploratory-gpu/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LinearRegression, Perceptron, RidgeClassifier, SGDClassifier, LassoCV\n",
    "from sklearn.svm import SVC, LinearSVC, SVR\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \n",
    "from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn import metrics\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# NN models\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras import optimizers\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import torch\n",
    "import transformers as ppb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30100a0e-5ea6-4c08-aef5-0f8999f51452",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4304d0f0-3d1a-4836-a17a-c45099f0f7da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../../data/raw/raw.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e9180c5-16bb-469a-a634-1f82bc1eed4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>published date</th>\n",
       "      <th>url</th>\n",
       "      <th>publisher</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plight of homeless deepens as Turkey-Syria ear...</td>\n",
       "      <td>Plight of homeless deepens as Turkey-Syria ear...</td>\n",
       "      <td>Thu, 09 Feb 2023 12:23:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiaGh0d...</td>\n",
       "      <td>{'href': 'https://www.reuters.com', 'title': '...</td>\n",
       "      <td>Summary\\n\\nSummary Companies Death toll reache...</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Zelenskyy makes heartfelt call for Ukraine's E...</td>\n",
       "      <td>Zelenskyy makes heartfelt call for Ukraine's E...</td>\n",
       "      <td>Thu, 09 Feb 2023 14:55:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiQGh0d...</td>\n",
       "      <td>{'href': 'https://www.cnbc.com', 'title': 'CNBC'}</td>\n",
       "      <td>Ukrainian President Volodymyr Zelensky and Pre...</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Huge haul of cocaine floating at sea seized - CNN</td>\n",
       "      <td>Huge haul of cocaine floating at sea seized  C...</td>\n",
       "      <td>Thu, 09 Feb 2023 11:17:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiUGh0d...</td>\n",
       "      <td>{'href': 'https://www.cnn.com', 'title': 'CNN'}</td>\n",
       "      <td>CNN 窶能\n\\nMore than 3 tons of cocaine floating ...</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5 things to know for February 9: Earthquake, C...</td>\n",
       "      <td>5 things to know for February 9: Earthquake, C...</td>\n",
       "      <td>Thu, 09 Feb 2023 11:53:00 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMiSGh0d...</td>\n",
       "      <td>{'href': 'https://www.cnn.com', 'title': 'CNN'}</td>\n",
       "      <td>CNN 窶能\n\\nGet '5 Things' in your inbox If your ...</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kremlin Endorses Report on U.S. Involvement in...</td>\n",
       "      <td>Kremlin Endorses Report on U.S. Involvement in...</td>\n",
       "      <td>Thu, 09 Feb 2023 11:36:32 GMT</td>\n",
       "      <td>https://news.google.com/rss/articles/CBMicmh0d...</td>\n",
       "      <td>{'href': 'https://www.themoscowtimes.com', 'ti...</td>\n",
       "      <td>The Kremlin on Thursday endorsed a blog post b...</td>\n",
       "      <td>WORLD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  Plight of homeless deepens as Turkey-Syria ear...   \n",
       "1  Zelenskyy makes heartfelt call for Ukraine's E...   \n",
       "2  Huge haul of cocaine floating at sea seized - CNN   \n",
       "3  5 things to know for February 9: Earthquake, C...   \n",
       "4  Kremlin Endorses Report on U.S. Involvement in...   \n",
       "\n",
       "                                         description  \\\n",
       "0  Plight of homeless deepens as Turkey-Syria ear...   \n",
       "1  Zelenskyy makes heartfelt call for Ukraine's E...   \n",
       "2  Huge haul of cocaine floating at sea seized  C...   \n",
       "3  5 things to know for February 9: Earthquake, C...   \n",
       "4  Kremlin Endorses Report on U.S. Involvement in...   \n",
       "\n",
       "                  published date  \\\n",
       "0  Thu, 09 Feb 2023 12:23:00 GMT   \n",
       "1  Thu, 09 Feb 2023 14:55:00 GMT   \n",
       "2  Thu, 09 Feb 2023 11:17:00 GMT   \n",
       "3  Thu, 09 Feb 2023 11:53:00 GMT   \n",
       "4  Thu, 09 Feb 2023 11:36:32 GMT   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://news.google.com/rss/articles/CBMiaGh0d...   \n",
       "1  https://news.google.com/rss/articles/CBMiQGh0d...   \n",
       "2  https://news.google.com/rss/articles/CBMiUGh0d...   \n",
       "3  https://news.google.com/rss/articles/CBMiSGh0d...   \n",
       "4  https://news.google.com/rss/articles/CBMicmh0d...   \n",
       "\n",
       "                                           publisher  \\\n",
       "0  {'href': 'https://www.reuters.com', 'title': '...   \n",
       "1  {'href': 'https://www.cnbc.com', 'title': 'CNBC'}   \n",
       "2    {'href': 'https://www.cnn.com', 'title': 'CNN'}   \n",
       "3    {'href': 'https://www.cnn.com', 'title': 'CNN'}   \n",
       "4  {'href': 'https://www.themoscowtimes.com', 'ti...   \n",
       "\n",
       "                                                text  topic  \n",
       "0  Summary\\n\\nSummary Companies Death toll reache...  WORLD  \n",
       "1  Ukrainian President Volodymyr Zelensky and Pre...  WORLD  \n",
       "2  CNN 窶能\n\\nMore than 3 tons of cocaine floating ...  WORLD  \n",
       "3  CNN 窶能\n\\nGet '5 Things' in your inbox If your ...  WORLD  \n",
       "4  The Kremlin on Thursday endorsed a blog post b...  WORLD  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edb6a69-4aa5-42b1-af85-fa6578ee3667",
   "metadata": {},
   "source": [
    "# Category Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f10540f-f759-4848-8321-054d4142eb70",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ENTERTAINMENT    490\n",
       "NATION           470\n",
       "TECHNOLOGY       454\n",
       "BUSINESS         437\n",
       "HEALTH           404\n",
       "WORLD            391\n",
       "SCIENCE          388\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.topic.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7192f7d-feee-4655-a7ac-08e8513c7838",
   "metadata": {},
   "source": [
    "Luckily a pretty even distribution especially given the nature of the scraper.\n",
    "\n",
    "# ML Task\n",
    "\n",
    "Train a classifier for the categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54c38e64-b35e-42e6-a847-e69ebac75a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = df[['topic', 'title']]\n",
    "# # Manual OneHotEncoding because sklearns was taking me a bit.\n",
    "# for topic in df.topic.unique():\n",
    "#     df.loc[:,topic] = (df.topic == topic).astype(int)\n",
    "    \n",
    "    \n",
    "# df.drop(['topic'], axis=1, inplace=True)\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df.topic)\n",
    "\n",
    "df.topic = le.transform(df.topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8294a6-4a05-45f7-b238-65aa05c7ced5",
   "metadata": {},
   "source": [
    "## BERT: Data preparing and modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f7d2905-b69f-4dab-a316-a9ef3d157676",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_transform.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# For pre-trained DistilBERT:\n",
    "model_class, tokenizer_class, pretrained_weights = (ppb.DistilBertModel, ppb.DistilBertTokenizer, 'distilbert-base-uncased')\n",
    "\n",
    "# Other models: https://huggingface.co/transformers/pretrained_models.html\n",
    "\n",
    "# Load pretrained model/tokenizer\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)\n",
    "model = model_class.from_pretrained(pretrained_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59503b3c-35d4-4067-9612-ea0b7f01aa67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3034, 39)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenization the sentences - break them up into word and subwords in the format BERT is comfortable with\n",
    "tokenized = df['title'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))\n",
    "\n",
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)\n",
    "\n",
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ea047b6-c94f-4411-832f-34ba1d3d2923",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3034, 39)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creation variable to ignore (mask) the data padding\n",
    "attention_mask = np.where(padded != 0, 1, 0)\n",
    "print(attention_mask.shape)\n",
    "attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "745971f6-99e0-41dd-8e8e-733c8d358e87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Modeling\n",
    "input_ids = torch.tensor(padded).to(torch.int64)\n",
    "attention_mask = torch.tensor(attention_mask).to(torch.int64)\n",
    "\n",
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids, attention_mask=attention_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee4a896-4e3c-4b16-b386-5be9bbf95b83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Last hidden states\n",
    "features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82e818b3-1767-4a2d-8165-74ab56e17cee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.36741638, -0.08812499, -0.24700838, ..., -0.40141216,\n",
       "         0.3454349 , -0.01795575],\n",
       "       [-0.23706903, -0.07861285, -0.0465744 , ..., -0.30821347,\n",
       "         0.40797278,  0.14277637],\n",
       "       [-0.22179267, -0.3567314 , -0.11802878, ..., -0.3067955 ,\n",
       "         0.53071135,  0.12337755],\n",
       "       ...,\n",
       "       [-0.42635   , -0.10425763, -0.02006005, ..., -0.16933376,\n",
       "         0.6849675 ,  0.04143865],\n",
       "       [ 0.01284773, -0.0919233 , -0.10722934, ..., -0.24347584,\n",
       "         0.54869324,  0.25608742],\n",
       "       [-0.30738497, -0.11996962,  0.07331155, ..., -0.26930004,\n",
       "         0.5723503 ,  0.21982545]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee68fff4-e11d-49ea-a26b-f5f3ad0d3153",
   "metadata": {},
   "source": [
    "## Text classification and prediction by many models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc74ca87-1c41-4684-a2ae-c6256ba3aa5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_state = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c6c5dad-91b2-4b55-97f4-f78f04805462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Set parameters of models\n",
    "models = pd.DataFrame(columns = ['name', 'model', 'param_grid'])\n",
    "\n",
    "# # Linear Regression\n",
    "# n = 0\n",
    "# models.loc[n, 'name'] = 'Linear Regression'\n",
    "# models.at[n, 'model'] = LinearRegression()\n",
    "# models.at[n, 'param_grid'] = {}\n",
    "\n",
    "# # Logistic Regression\n",
    "# n = 1\n",
    "# models.loc[n, 'name'] = 'Logistic Regression'\n",
    "# models.at[n, 'model'] = LogisticRegression()\n",
    "# models.at[n, 'param_grid'] = {'C': np.linspace(0.0001, 100, 20)\n",
    "#                              }\n",
    "\n",
    "# Support Vector Machines\n",
    "n = 2\n",
    "models.loc[n, 'name'] = 'Support Vector Machines'\n",
    "models.at[n, 'model'] = SVC()\n",
    "models.at[n, 'param_grid'] = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "                              'tol': [1e-3]\n",
    "                             }\n",
    "\n",
    "# Linear SVC\n",
    "n = 3\n",
    "models.loc[n, 'name'] = 'Linear SVC'\n",
    "models.at[n, 'model'] = LinearSVC()\n",
    "models.at[n, 'param_grid'] = {'dual':[False],\n",
    "                              'C': np.linspace(1, 15, 15)\n",
    "                             }\n",
    "\n",
    "# Random Forest Classifier\n",
    "n = 4\n",
    "models.loc[n, 'name'] = 'Random Forest Classifier'\n",
    "models.at[n, 'model'] = RandomForestClassifier()\n",
    "models.at[n, 'param_grid'] = {'n_estimators': [40, 50, 60, 100, 500], \n",
    "                              'min_samples_split': [30, 40, 50, 100, 200], \n",
    "                              'min_samples_leaf': [10, 12, 15, 20, 50],\n",
    "                              'max_features': ['auto'], \n",
    "                              'max_depth': [3, 4, 5, 6], \n",
    "                              'criterion': ['gini'], \n",
    "                              'bootstrap': [False]                              \n",
    "                             }\n",
    "\n",
    "# Bagging Classifier\n",
    "n = 5\n",
    "models.loc[n, 'name'] = 'Bagging Classifier'\n",
    "models.at[n, 'model'] = BaggingClassifier()\n",
    "models.at[n, 'param_grid'] = {'max_features': np.linspace(0.05, 0.8, 1),\n",
    "                              'n_estimators': [3, 4, 5, 6],\n",
    "                              'warm_start' : [False]\n",
    "                             }\n",
    "\n",
    "# XGB Classifier\n",
    "n = 6\n",
    "models.loc[n, 'name'] = 'XGB Classifier'\n",
    "models.at[n, 'model'] = xgb.XGBClassifier(objective='binary:hinge')  # or binary:logistic\n",
    "models.at[n, 'param_grid'] = {'n_estimators': [50, 70, 90], \n",
    "                              'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                              'max_depth': [3, 4, 5]\n",
    "                             }\n",
    "\n",
    "# LGBM Classifier\n",
    "# n = 7\n",
    "# models.loc[n, 'name'] = 'LGBM Classifier'\n",
    "# models.at[n, 'model'] = lgb.LGBMClassifier(boosting_type='gbdt',  \n",
    "#                                            objective='binary' \n",
    "#                                            )\n",
    "# models.at[n, 'param_grid'] = {'n_estimators': [50, 100, 500, 1000], \n",
    "#                               'num_leaves': [30, 50, 100, 200], \n",
    "#                               'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.5]\n",
    "#                              }\n",
    "\n",
    "# # MLP Classifier\n",
    "# n = 8\n",
    "# models.loc[n, 'name'] = 'MLPClassifier'\n",
    "# models.at[n, 'model'] = MLPClassifier()\n",
    "# models.at[n, 'param_grid'] = {'hidden_layer_sizes': [i for i in range(2,10)],\n",
    "#                               'solver': ['sgd'],\n",
    "#                               'learning_rate': ['adaptive'],\n",
    "#                               'max_iter': [1000, 2000]\n",
    "#                              }\n",
    "\n",
    "# Avg values\n",
    "models.loc[9, 'name'] = 'Mean values'\n",
    "\n",
    "# Max values\n",
    "models.loc[10, 'name'] = 'Max values'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "691b7231-7abc-4437-9db9-3e1e1dedc3a3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>model</th>\n",
       "      <th>param_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>{'kernel': ['linear', 'poly', 'rbf', 'sigmoid'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>LinearSVC()</td>\n",
       "      <td>{'dual': [False], 'C': [1.0, 2.0, 3.0, 4.0, 5....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>{'n_estimators': [40, 50, 60, 100, 500], 'min_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>BaggingClassifier()</td>\n",
       "      <td>{'max_features': [0.05], 'n_estimators': [3, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>XGBClassifier(base_score=None, booster=None, c...</td>\n",
       "      <td>{'n_estimators': [50, 70, 90], 'learning_rate'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean values</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Max values</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  \\\n",
       "2    Support Vector Machines   \n",
       "3                 Linear SVC   \n",
       "4   Random Forest Classifier   \n",
       "5         Bagging Classifier   \n",
       "6             XGB Classifier   \n",
       "9                Mean values   \n",
       "10                Max values   \n",
       "\n",
       "                                                model  \\\n",
       "2                                               SVC()   \n",
       "3                                         LinearSVC()   \n",
       "4                            RandomForestClassifier()   \n",
       "5                                 BaggingClassifier()   \n",
       "6   XGBClassifier(base_score=None, booster=None, c...   \n",
       "9                                                 NaN   \n",
       "10                                                NaN   \n",
       "\n",
       "                                           param_grid  \n",
       "2   {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'...  \n",
       "3   {'dual': [False], 'C': [1.0, 2.0, 3.0, 4.0, 5....  \n",
       "4   {'n_estimators': [40, 50, 60, 100, 500], 'min_...  \n",
       "5   {'max_features': [0.05], 'n_estimators': [3, 4...  \n",
       "6   {'n_estimators': [50, 70, 90], 'learning_rate'...  \n",
       "9                                                 NaN  \n",
       "10                                                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c5850767-96da-4e8a-ba19-2659cca1161b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def model_prediction(models, features, labels, test_size, verbose):\n",
    "    # Models training and data prediction for all models from DataFrame models\n",
    "    \n",
    "    # Splitting train data for model tuning with cross-validation\n",
    "    #cv_train = ShuffleSplit(n_splits=cv_n_split, test_size=0.2, random_state=random_state)\n",
    "    train_features, test_features, train_labels, test_labels = train_test_split(features, \n",
    "                                                                                labels, \n",
    "                                                                                test_size=test_size,\n",
    "                                                                                random_state=random_state)\n",
    "    # Total list of prediction by all models\n",
    "    total_train_pred = []\n",
    "    total_test_pred = []\n",
    "    \n",
    "    # Results\n",
    "    results = models[['name']].copy()\n",
    "    results['acc_train'] = results['acc_test'] = 0\n",
    "\n",
    "    for i in models.index[:-2]:\n",
    "        # Training\n",
    "        model = GridSearchCV(models.at[i, 'model'], models.at[i, 'param_grid'])\n",
    "        model.fit(train_features, train_labels)\n",
    "        \n",
    "        # Prediction\n",
    "        train_pred = model.predict(train_features).round(0).astype('int')\n",
    "        total_train_pred.append(train_pred)\n",
    "        test_pred = model.predict(test_features).round(0).astype('int')\n",
    "        total_test_pred.append(test_pred)\n",
    "        \n",
    "        # Scoring\n",
    "        acc_train = accuracy_score(train_labels, train_pred)\n",
    "        acc_test = accuracy_score(test_labels, test_pred)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f\"Model - {models.loc[i, 'name']}\")\n",
    "            print(\"Best parameters:\", model.best_params_)\n",
    "            print(\"Accuracy for training data: %0.3f\" % acc_train)\n",
    "            print(\"Accuracy for test data: %0.3f\" % acc_test)\n",
    "            print('\\n')\n",
    "        \n",
    "        # Save results\n",
    "        results.loc[i,'acc_train'] = acc_train\n",
    "        results.loc[i,'acc_test'] = acc_test\n",
    "\n",
    "    # MEAN values\n",
    "    # Calc prediction\n",
    "    mean_train_pred = (np.mean(np.array(total_train_pred), axis=0)).astype(int)\n",
    "    mean_test_pred = (np.mean(np.array(total_test_pred), axis=0)).astype(int)    \n",
    "    \n",
    "    # Scoring\n",
    "    acc_train = accuracy_score(train_labels, mean_train_pred)\n",
    "    acc_test = accuracy_score(test_labels, mean_test_pred)\n",
    "    if verbose:\n",
    "        print(f\"Mean prediction values\")\n",
    "        print(\"Accuracy for training data: %0.3f\" % acc_train)\n",
    "        print(\"Accuracy for test data: %0.3f\" % acc_test)\n",
    "        \n",
    "    # Save results\n",
    "    n = len(results)-2\n",
    "    results.loc[n,'acc_train'] = acc_train\n",
    "    results.loc[n,'acc_test'] = acc_test\n",
    "\n",
    "    # MAX values\n",
    "    # Calc prediction\n",
    "    max_train_pred = (np.max(np.array(total_train_pred), axis=0))\n",
    "    max_test_pred = (np.max(np.array(total_test_pred), axis=0))\n",
    "    \n",
    "    # Scoring\n",
    "    acc_train = accuracy_score(train_labels, max_train_pred)\n",
    "    acc_test = accuracy_score(test_labels, max_test_pred)\n",
    "    if verbose:\n",
    "        print(f\"Maximum prediction values\")\n",
    "        print(\"Accuracy for training data: %0.3f\" % acc_train)\n",
    "        print(\"Accuracy for test data: %0.3f\" % acc_test)\n",
    "    \n",
    "    # Save results\n",
    "    n = len(results)-1\n",
    "    results.loc[n,'acc_train'] = acc_train\n",
    "    results.loc[n,'acc_test'] = acc_test\n",
    "\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "658b7645-db98-4045-94c0-1f4e522ce53a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def target_prediction(models, df, features, test_size=0.2, verbose=True):\n",
    "    # Text classification model and prediction for given feature \"target\" (with labels) in df\n",
    "    \n",
    "    # Target\n",
    "    labels = df.topic\n",
    "    \n",
    "#     # Extracting the number of examples of each class\n",
    "#     Relevant_len = df[labels == 1].shape[0]\n",
    "#     Not_len = df[df[target] == 0].shape[0]\n",
    "    \n",
    "#     # Draw bar plot\n",
    "#     plt.rcParams['figure.figsize'] = (7, 5)\n",
    "#     plt.bar(10, Relevant_len, 3, label=\"Relevant\", color='green')\n",
    "#     plt.bar(15, Not_len, 3, label=\"Not\", color='red')\n",
    "#     plt.legend(loc='upper center')\n",
    "#     plt.ylabel('Number of examples')\n",
    "#     plt.title('Proportion of examples for ' + target)\n",
    "#     plt.show()\n",
    "    \n",
    "    # Models training, prediction and save results\n",
    "    results = model_prediction(models, features, labels, test_size, verbose=verbose)\n",
    "    results = results.sort_values(by=['acc_test', 'acc_train'], ascending=False)\n",
    "    results.to_csv(f'models-scoring.csv', index=False)\n",
    "    display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "72cfcbba-f4f4-4a42-89c5-23e4773c617a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving NLP Classification tasks\n",
      "Model - Support Vector Machines\n",
      "Best parameters: {'kernel': 'linear', 'tol': 0.001}\n",
      "Accuracy for training data: 0.999\n",
      "Accuracy for test data: 0.984\n",
      "\n",
      "\n",
      "Model - Linear SVC\n",
      "Best parameters: {'C': 13.0, 'dual': False}\n",
      "Accuracy for training data: 0.999\n",
      "Accuracy for test data: 0.982\n",
      "\n",
      "\n",
      "Model - Random Forest Classifier\n",
      "Best parameters: {'bootstrap': False, 'criterion': 'gini', 'max_depth': 6, 'max_features': 'auto', 'min_samples_leaf': 15, 'min_samples_split': 30, 'n_estimators': 500}\n",
      "Accuracy for training data: 0.966\n",
      "Accuracy for test data: 0.942\n",
      "\n",
      "\n",
      "Model - Bagging Classifier\n",
      "Best parameters: {'max_features': 0.05, 'n_estimators': 5, 'warm_start': False}\n",
      "Accuracy for training data: 0.997\n",
      "Accuracy for test data: 0.954\n",
      "\n",
      "\n",
      "Model - XGB Classifier\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 70}\n",
      "Accuracy for training data: 0.999\n",
      "Accuracy for test data: 0.979\n",
      "\n",
      "\n",
      "Mean prediction values\n",
      "Accuracy for training data: 0.979\n",
      "Accuracy for test data: 0.943\n",
      "Maximum prediction values\n",
      "Accuracy for training data: 0.983\n",
      "Accuracy for test data: 0.948\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Support Vector Machines</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.983526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVC</td>\n",
       "      <td>0.999451</td>\n",
       "      <td>0.981878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGB Classifier</td>\n",
       "      <td>0.982967</td>\n",
       "      <td>0.948105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging Classifier</td>\n",
       "      <td>0.979121</td>\n",
       "      <td>0.943163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Random Forest Classifier</td>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.942339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mean values</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Max values</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        name  acc_train  acc_test\n",
       "2    Support Vector Machines   0.999451  0.983526\n",
       "3                 Linear SVC   0.999451  0.981878\n",
       "6             XGB Classifier   0.982967  0.948105\n",
       "5         Bagging Classifier   0.979121  0.943163\n",
       "4   Random Forest Classifier   0.966484  0.942339\n",
       "9                Mean values   0.000000  0.000000\n",
       "10                Max values   0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Solving NLP Classification tasks\n",
    "print('Solving NLP Classification tasks')\n",
    "target_prediction(models, df, features, test_size=0.4, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
